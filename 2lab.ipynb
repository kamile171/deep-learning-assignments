{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IbXjeH1atn6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR-f-RgmLQTZ",
        "outputId": "8a08531b-8718-40a1-df2e-3acfddd7c8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3z6HjnbLIe7"
      },
      "outputs": [],
      "source": [
        "!pip install oidv6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade oidv6"
      ],
      "metadata": {
        "id": "QMuM-7ZyLQCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!oidv6 downloader en --dataset drive/MyDrive/foldr --type_data train --classes Tomato Pumpkin Carrot Cucumber Broccoli --limit 400\n"
      ],
      "metadata": {
        "id": "n1SYuII_LUHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!oidv6 downloader en --dataset drive/MyDrive/foldr --type_data test --classes Lemon --limit 100"
      ],
      "metadata": {
        "id": "tdQhA6gflNbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Class mapping\n",
        "number_of_classes = 5\n",
        "classes = [\"broccoli\", \"carrot\", \"cucumber\", \"lemon\", \"pumpkin\"]\n",
        "\n",
        "#A dictionary is made by finding a corresponding class index by providing the predefined 5 class names\n",
        "\n",
        "with open('/content/drive/MyDrive/pics/classes.txt', 'r') as f:\n",
        "    class_names = [ln.strip() for ln in f]\n",
        "\n",
        "class_mapping = {}\n",
        "for i, class_name in enumerate(class_names):\n",
        "    if class_name.lower() in [c.lower() for c in classes]:\n",
        "        index = [c.lower() for c in classes].index(class_name.lower())\n",
        "        class_mapping[class_name.lower()] = {'index': i}\n",
        "\n",
        "print(class_mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74QIw_khR4lm",
        "outputId": "7da625e5-03cf-4b27-9f73-73fcdc8b4cd6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'broccoli': {'index': 0}, 'carrot': {'index': 1}, 'cucumber': {'index': 2}, 'lemon': {'index': 3}, 'pumpkin': {'index': 4}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOmSrPNggqFh",
        "outputId": "90f7d438-64e1-4b7c-da0e-7f5c1106db32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset\n",
        "import numpy as np\n",
        "import re\n",
        "import glob\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import PIL\n",
        "from torchvision import transforms\n",
        "import os\n",
        "\n",
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, image_dir, transforms=transforms):\n",
        "        self.image_dir = image_dir\n",
        "        self.labels = []\n",
        "        self.class_names = []\n",
        "        self.transforms = transforms\n",
        "        \n",
        "\n",
        "        #Retrieving image files and their label paths, folder doesn't necessarily have to contain images of its name\n",
        "        self.class1_files = glob.glob(self.image_dir + \"/{}/*.jpg\".format(classes[0].lower()))\n",
        "        self.class1_label_paths = glob.glob(self.image_dir + \"/{}/labels/*.txt\".format(classes[0].lower()))\n",
        "        self.class2_files = glob.glob(self.image_dir + \"/{}/*.jpg\".format(classes[1].lower()))\n",
        "        self.class2_label_paths = glob.glob(self.image_dir + \"/{}/labels/*.txt\".format(classes[1].lower()))\n",
        "        self.class3_files = glob.glob(self.image_dir + \"/{}/*.jpg\".format(classes[2].lower()))\n",
        "        self.class3_label_paths = glob.glob(self.image_dir + \"/{}/labels/*.txt\".format(classes[2].lower()))\n",
        "        self.class4_files = glob.glob(self.image_dir + \"/{}/*.jpg\".format(classes[3].lower()))\n",
        "        self.class4_label_paths = glob.glob(self.image_dir + \"/{}/labels/*.txt\".format(classes[3].lower()))\n",
        "        self.class5_files = glob.glob(self.image_dir + \"/{}/*.jpg\".format(classes[4].lower()))\n",
        "        self.class5_label_paths = glob.glob(self.image_dir + \"/{}/labels/*.txt\".format(classes[4].lower()))\n",
        "\n",
        "        self.class1 = len(self.class1_files)\n",
        "        #print(self.class1)\n",
        "        self.class2 = len(self.class2_files)\n",
        "        #print(self.class2)\n",
        "        self.class3 = len(self.class3_files)\n",
        "        #print(self.class3)\n",
        "        self.class4 = len(self.class4_files)\n",
        "        #print(self.class3)\n",
        "        self.class5 = len(self.class5_files)\n",
        "        #print(self.class3)\n",
        "\n",
        "        #print(self.class3)\n",
        "    \n",
        "        self.files = self.class1_files + self.class2_files + self.class3_files +  self.class4_files + self.class5_files\n",
        "       # print(self.files)\n",
        "        self.label_paths = self.class1_label_paths + self.class2_label_paths + self.class3_label_paths + self.class4_label_paths + self.class5_label_paths\n",
        "        #print(self.label_paths)\n",
        "\n",
        "        \n",
        "       #Each image has a corresponding label text file, therefore class names are extracted into a list \n",
        "        for label_file in self.label_paths:\n",
        "            #img_name = os.path.splitext(os.path.basename(label_file))[0]\n",
        "            with open(label_file, 'r') as f:\n",
        "              label_parts = f.readline().strip().split(' ')\n",
        "              label_name = label_parts[0]\n",
        "              self.class_names.append(label_name)\n",
        "        #print(self.class_names)\n",
        "\n",
        "        #In order to keep labels as integers(indexes, corresponding in class file), \n",
        "        #class names are mapped to their index values in the dictionary\n",
        "        for label in self.class_names:\n",
        "            label_data = class_mapping.get(label.lower())\n",
        "            self.labels.append(label_data['index'])\n",
        "        #print(self.labels)\n",
        "\n",
        "        #Image and label order is mixed\n",
        "        self.order =  [x for x in np.random.permutation(len(self.labels))]\n",
        "        self.files = [self.files[x] for x in self.order]\n",
        "        self.labels = [self.labels[x] for x in self.order]\n",
        "        #print(self.labels)\n",
        "\n",
        "    def __len__(self):\n",
        "         return (len(self.labels))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        files = self.files[index]\n",
        "\n",
        "        img = Image.open(files).convert(\"RGB\")\n",
        "        img = self.transforms(img)\n",
        "\n",
        "        label = self.labels[index]\n",
        "\n",
        "        return img, label\n",
        "\n",
        "\n",
        "#Defining transformations which are later going to be applied on train dataset\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "transformTrain = transforms.Compose([\n",
        "            torchvision.transforms.Resize((224,224)),\n",
        "            #torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
        "            torchvision.transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomGrayscale(),\n",
        "            transforms.RandomRotation(20),\n",
        "            #transforms.ColorJitter(brightness = 0.4, saturation = 0.1, hue = 0.1),\n",
        "            #torchvision.transforms.RandomRotation(20, resample=PIL.Image.BILINEAR),\n",
        "            transforms.ToTensor(),\n",
        "\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "transformVal = transforms.Compose([\n",
        "            torchvision.transforms.Resize((224,224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "#Creating train and validation datasets\n",
        "#train_image_dir = \"/content/drive/MyDrive/foldr/train\"\n",
        "train_image_dir = \"/content/drive/MyDrive/foldr/train\"\n",
        "train_dataset = ImageDataset(image_dir=train_image_dir, transforms=transformTrain)\n",
        "\n",
        "#val_image_dir = \"/content/drive/MyDrive/foldr/validation\"\n",
        "val_image_dir = \"/content/drive/MyDrive/foldr/test\"\n",
        "val_dataset = ImageDataset(image_dir=val_image_dir, transforms=transformVal)"
      ],
      "metadata": {
        "id": "IaR902jeR_Du",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZcr0FrdgdS_",
        "outputId": "9a4f1f10-52d2-457c-a76d-a849f63e1d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_dataset)"
      ],
      "metadata": {
        "id": "P_Mutrp0dbEQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e731622a-adb4-4222-fb16-fdf33f53e92b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "470"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {device}')"
      ],
      "metadata": {
        "id": "X26kAlXTLg5-",
        "outputId": "e6b1ec7e-1dee-4858-af2e-a2f4f14e1cbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ConvNetS\n",
        "#everything is the same as in ConvNet, only a softmax is added after the last fully connected layer\n",
        "class ConvNetS(torch.nn.Module):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = torch.nn.Conv2d(input_shape[0], 16, (3, 3), padding='same')\n",
        "        self.bn1 = torch.nn.BatchNorm2d(16)\n",
        "        self.conv2 = torch.nn.Conv2d(16, 32, (3, 3), padding='same')\n",
        "        self.bn2 = torch.nn.BatchNorm2d(32)\n",
        "        self.conv3 = torch.nn.Conv2d(32, 64, (3, 3), padding='same')\n",
        "        self.bn3 = torch.nn.BatchNorm2d(64)\n",
        "        self.fc1 = torch.nn.Linear(64 * (input_shape[1] // 8) * (input_shape[2] // 8), 256)\n",
        "        self.bn4 = torch.nn.BatchNorm1d(256)\n",
        "        self.fc2 = torch.nn.Linear(256, 128)\n",
        "        self.bn5 = torch.nn.BatchNorm1d(128)\n",
        "        self.fc3 = torch.nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x)\n",
        "        y = self.bn1(y)\n",
        "        y = torch.nn.ReLU()(y)\n",
        "        y = torch.nn.MaxPool2d((2, 2), (2, 2))(y)\n",
        "        y = self.conv2(y)\n",
        "        y = self.bn2(y)\n",
        "        y = torch.nn.ReLU()(y)\n",
        "        y = torch.nn.MaxPool2d((2, 2), (2, 2))(y)\n",
        "        y = self.conv3(y)\n",
        "        y = self.bn3(y)\n",
        "        y = torch.nn.ReLU()(y)\n",
        "        y = torch.nn.MaxPool2d((2, 2), (2, 2))(y)\n",
        "        y = torch.nn.Flatten()(y)\n",
        "        y = self.fc1(y)\n",
        "        y = self.bn4(y)\n",
        "        y = torch.nn.ReLU()(y)\n",
        "        y = self.fc2(y)\n",
        "        y = self.bn5(y)\n",
        "        y = torch.nn.ReLU()(y)\n",
        "        y = self.fc3(y)\n",
        "        y = torch.nn.Softmax(dim=1)(y)\n",
        "\n",
        "        return y\n"
      ],
      "metadata": {
        "id": "iEUkRV3eTNQI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train and validate\n",
        "#Training for 15 epochs, after 10 epochs, usually overfitting starts \n",
        "predicted_list = []\n",
        "ground_truth_list = []\n",
        "\n",
        "def train(model, train_dataloader, optimizer, loss_func, epoch_count=15, print_freq=1):\n",
        "    model.train()\n",
        "    for epoch in range(epoch_count):\n",
        "        total_loss = 0\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for images, labels in train_dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(images)\n",
        "            loss = loss_func(preds, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(preds, 1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        epoch_loss = total_loss / len(train_dataloader)\n",
        "        epoch_acc = total_correct / total_samples\n",
        "        if (epoch + 1) % print_freq == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{epoch_count}], Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}\")\n",
        "        val_loss, val_acc, predicted_list_local, ground_truth_list_local = validate(model, val_dataloader, loss_func)\n",
        "        if (epoch + 1) % print_freq == 0:\n",
        "          print(f\"Epoch [{epoch+1}/{epoch_count}], Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "        tp_local, fp_local, fn_local = calcMetrics(ground_truth_list_local, predicted_list_local)\n",
        "        #print(predicted_list_local)\n",
        "        #print(predicted_list)\n",
        "        if (epoch + 1) % 5 == 0 or (epoch + 1) == 1:\n",
        "          for i in range(0, number_of_classes):\n",
        "              #print(tp_local[classes[i].lower()], tn_local[classes[i].lower()], fp_local[classes[i].lower()], fn_local[classes[i].lower()])\n",
        "              metrics = calculate_metrics(tp_local[classes[i].lower()], fp_local[classes[i].lower()], fn_local[classes[i].lower()])\n",
        "              print(classes[i].lower(), ': ', metrics)\n",
        "          print_confusion_matrix(ground_truth_list_local, predicted_list_local, classes)\n",
        "              \n",
        " \n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate(model, val_dataloader, loss_func):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        " \n",
        "    predicted_list_local = []\n",
        "    ground_truth_list_local = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            preds = model(images)\n",
        "            loss = loss_func(preds, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(preds, 1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "            for i in range(len(predicted)):\n",
        "              ground_truth_index = labels[i].item()\n",
        "              ground_truth_list.append(ground_truth_index)\n",
        "              ground_truth_list_local.append(ground_truth_index)\n",
        "              predicted_index = predicted[i].item()\n",
        "              predicted_list.append(predicted_index)\n",
        "              predicted_list_local.append(predicted_index)\n",
        "\n",
        "\n",
        "    epoch_loss = total_loss / len(val_dataloader)\n",
        "    epoch_acc = total_correct / total_samples\n",
        "\n",
        "    return epoch_loss, epoch_acc, predicted_list_local, ground_truth_list_local\n",
        "    "
      ],
      "metadata": {
        "id": "QFbUjtpLm2Qg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title TP FP FN function\n",
        "\n",
        "#Obtaining TP FP FN values to calculate other metrics\n",
        "def calcMetrics(ground_truth_list, predicted_list):\n",
        "  tp_local = {classes[0].lower(): 0, classes[1].lower(): 0, classes[2].lower(): 0, classes[3].lower(): 0, classes[4].lower(): 0}\n",
        "  #tn_local = {classes[0].lower(): 0, classes[1].lower(): 0, classes[2].lower(): 0, classes[3].lower(): 0, classes[4].lower(): 0}\n",
        "  fp_local = {classes[0].lower(): 0, classes[1].lower(): 0, classes[2].lower(): 0, classes[3].lower(): 0, classes[4].lower(): 0}\n",
        "  fn_local = {classes[0].lower(): 0, classes[1].lower(): 0, classes[2].lower(): 0, classes[3].lower(): 0, classes[4].lower(): 0}\n",
        "  \n",
        "  for i in range(len(ground_truth_list)):\n",
        "      \n",
        "      current_ground_truth = ground_truth_list[i]\n",
        "      current_predicted = predicted_list[i]\n",
        "    \n",
        "      gt_class_name = [k for k, v in class_mapping.items() if v['index'] == current_ground_truth]\n",
        "      gt_class_name = gt_class_name[0]\n",
        "      pr_class_name = [k for k, v in class_mapping.items() if v['index'] == current_predicted]\n",
        "      pr_class_name = pr_class_name[0]\n",
        "\n",
        "    # print(current_ground_truth)\n",
        "    # print(gt_class_name)\n",
        "    # print(current_predicted)\n",
        "    # print(pr_class_name)\n",
        "\n",
        "      if current_predicted == current_ground_truth:\n",
        "          tp_local[gt_class_name] += 1\n",
        "      else:\n",
        "          fp_local[pr_class_name] += 1\n",
        "          fn_local[gt_class_name] += 1\n",
        "          \n",
        "  #print(tp_local, tn_local, fp_local, fn_local)\n",
        "  return tp_local, fp_local, fn_local\n"
      ],
      "metadata": {
        "id": "QnCOzXamo7fr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Metrics of each class and overall metrics\n",
        "\n",
        "def calculate_metrics(tp, fp, fn):\n",
        "  tn=0\n",
        "  metrics = {}\n",
        "  try:\n",
        "        metrics['accuracy'] = (tp + tn) / (tp + fp + tn + fn)\n",
        "  except ZeroDivisionError:\n",
        "        metrics['accuracy'] = 0.0\n",
        "  try:\n",
        "        metrics['recall'] = tp / (tp + fn)\n",
        "  except ZeroDivisionError:\n",
        "        metrics['recall'] = 0.0\n",
        "  try:\n",
        "        metrics['precision'] = tp / (tp + fp)\n",
        "  except ZeroDivisionError:\n",
        "        metrics['precision'] = 0.0\n",
        "  try:\n",
        "        metrics['f1'] = 2 * (metrics['precision'] * metrics['recall']) / (metrics['precision'] + metrics['recall'])\n",
        "  except ZeroDivisionError:\n",
        "        metrics['f1'] = 0.0\n",
        "\n",
        "  return metrics\n",
        "\n",
        "#Adding up separate class statistics\n",
        "def add_up_statistics(t_p, f_p, f_n):\n",
        "\n",
        "  statistics = {'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0}\n",
        "  \n",
        "  #add up tp\n",
        "  for i in range(0, number_of_classes):\n",
        "    statistics['tp'] = statistics['tp'] + t_p[classes[0].lower()]\n",
        "\n",
        "   #add up fp\n",
        "  for i in range(0, number_of_classes):\n",
        "    statistics['fp'] = statistics['fp'] + f_p[classes[0].lower()]\n",
        "\n",
        "   #add up fn\n",
        "  for i in range(0, number_of_classes):\n",
        "    statistics['fn'] = statistics['fn'] + f_n[classes[0].lower()]\n",
        "\n",
        "  return statistics\n",
        "\n",
        "def calculate_overall_metrics(conjoined_statistics):\n",
        "\n",
        "  tp = conjoined_statistics['tp']\n",
        "  tn = conjoined_statistics['tn']\n",
        "  fp = conjoined_statistics['fp']\n",
        "  fn = conjoined_statistics['fn']\n",
        "\n",
        "  metrics = {}\n",
        "  metrics['accuracy'] = (tp + tn) / (tp + fp + tn + fn)\n",
        "  metrics['recall'] = tp / (tp + fn)\n",
        "  metrics['precision'] = tp / (tp + fp)\n",
        "  metrics['f1'] = 2 * (metrics['precision'] * metrics['recall']) / (metrics['precision'] + metrics['recall'])\n",
        "\n",
        "  return metrics\n"
      ],
      "metadata": {
        "id": "MwRjVpHMnirR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Confusion matrix function\n",
        "def print_confusion_matrix(ground_truth_list, predicted_list, classes):\n",
        "    cm = [[0 for _ in range(len(classes))] for _ in range(len(classes))]\n",
        "    for i in range(len(ground_truth_list)):\n",
        "        cm[ground_truth_list[i]][predicted_list[i]] += 1\n",
        "\n",
        "    header = [\" \"] + classes\n",
        "    rows = [header] + [[classes[i]] + cm[i] for i in range(len(classes))]\n",
        "    max_len = max(len(str(x)) for row in rows for x in row) + 2\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    for row in rows:\n",
        "        print(\"\".join(str(x).ljust(max_len) for x in row))"
      ],
      "metadata": {
        "id": "3Emy5FUmuFLH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataloader\n",
        "train_batch_size=200\n",
        "val_batch_size=30\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=val_batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "ZPx5I5bq07Ph",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tp = {classes[0].lower(): 0, classes[1].lower(): 0, classes[2].lower(): 0, classes[3].lower(): 0, classes[4].lower(): 0}\n",
        "#tn = {classes[0].lower(): 0, classes[1].lower(): 0, classes[2].lower(): 0, classes[3].lower(): 0, classes[4].lower(): 0}\n",
        "fp = {classes[0].lower(): 0, classes[1].lower(): 0, classes[2].lower(): 0, classes[3].lower(): 0, classes[4].lower(): 0}\n",
        "fn = {classes[0].lower(): 0, classes[1].lower(): 0, classes[2].lower(): 0, classes[3].lower(): 0, classes[4].lower(): 0}\n",
        "\n",
        "index_list = [v['index'] for v in class_mapping.values() if v['index'] != -1]\n",
        "print(index_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLRwHj2KCvqz",
        "outputId": "f28df4e1-92fa-44ab-80ec-cf562724d965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNetS(train_dataset[0][0].shape, 5).to(device)\n",
        "print(f'Parameter count: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "train(model, train_dataloader, optimizer, loss_func, 15, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGxY_uuRD0MK",
        "outputId": "4c3973ea-01bb-45f5-8d28-a76a1ebc1cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter count: 12,903,429\n",
            "Epoch [1/15], Train Loss: 1.5455, Train Acc: 0.3400\n",
            "Epoch [1/15], Val Loss: 1.5754, Val Acc: 0.2489\n",
            "broccoli :  {'accuracy': 0.0, 'recall': 0.0, 'precision': 0.0, 'f1': 0.0}\n",
            "carrot :  {'accuracy': 0.0, 'recall': 0.0, 'precision': 0.0, 'f1': 0.0}\n",
            "cucumber :  {'accuracy': 0.0, 'recall': 0.0, 'precision': 0.0, 'f1': 0.0}\n",
            "lemon :  {'accuracy': 0.2315035799522673, 'recall': 0.97, 'precision': 0.23317307692307693, 'f1': 0.375968992248062}\n",
            "pumpkin :  {'accuracy': 0.16806722689075632, 'recall': 0.23529411764705882, 'precision': 0.37037037037037035, 'f1': 0.28776978417266186}\n",
            "Confusion Matrix:\n",
            "          broccoli  carrot    cucumber  lemon     pumpkin   \n",
            "broccoli  0         0         0         98        2         \n",
            "carrot    0         0         0         59        26        \n",
            "cucumber  0         0         0         97        3         \n",
            "lemon     0         0         0         97        3         \n",
            "pumpkin   0         0         0         65        20        \n",
            "Epoch [2/15], Train Loss: 1.5421, Train Acc: 0.3385\n",
            "Epoch [2/15], Val Loss: 1.4911, Val Acc: 0.3872\n",
            "Epoch [3/15], Train Loss: 1.4892, Train Acc: 0.3930\n",
            "Epoch [3/15], Val Loss: 1.4609, Val Acc: 0.3894\n",
            "Epoch [4/15], Train Loss: 1.4580, Train Acc: 0.4310\n",
            "Epoch [4/15], Val Loss: 1.3924, Val Acc: 0.4872\n",
            "Epoch [5/15], Train Loss: 1.4318, Train Acc: 0.4545\n",
            "Epoch [5/15], Val Loss: 1.3806, Val Acc: 0.5213\n",
            "broccoli :  {'accuracy': 0.4129032258064516, 'recall': 0.64, 'precision': 0.5378151260504201, 'f1': 0.5844748858447488}\n",
            "carrot :  {'accuracy': 0.3509933774834437, 'recall': 0.6235294117647059, 'precision': 0.44537815126050423, 'f1': 0.5196078431372549}\n",
            "cucumber :  {'accuracy': 0.31543624161073824, 'recall': 0.47, 'precision': 0.4895833333333333, 'f1': 0.47959183673469385}\n",
            "lemon :  {'accuracy': 0.27358490566037735, 'recall': 0.29, 'precision': 0.8285714285714286, 'f1': 0.42962962962962964}\n",
            "pumpkin :  {'accuracy': 0.3880597014925373, 'recall': 0.611764705882353, 'precision': 0.5148514851485149, 'f1': 0.5591397849462366}\n",
            "Confusion Matrix:\n",
            "          broccoli  carrot    cucumber  lemon     pumpkin   \n",
            "broccoli  64        14        16        2         4         \n",
            "carrot    3         53        1         0         28        \n",
            "cucumber  32        14        47        1         6         \n",
            "lemon     18        14        28        29        11        \n",
            "pumpkin   2         24        4         3         52        \n",
            "Epoch [6/15], Train Loss: 1.4361, Train Acc: 0.4590\n",
            "Epoch [6/15], Val Loss: 1.3922, Val Acc: 0.4957\n",
            "Epoch [7/15], Train Loss: 1.3899, Train Acc: 0.5125\n",
            "Epoch [7/15], Val Loss: 1.3594, Val Acc: 0.5255\n",
            "Epoch [8/15], Train Loss: 1.3775, Train Acc: 0.5165\n",
            "Epoch [8/15], Val Loss: 1.3506, Val Acc: 0.5489\n",
            "Epoch [9/15], Train Loss: 1.3732, Train Acc: 0.5250\n",
            "Epoch [9/15], Val Loss: 1.3372, Val Acc: 0.5489\n",
            "Epoch [10/15], Train Loss: 1.3551, Train Acc: 0.5475\n",
            "Epoch [10/15], Val Loss: 1.3348, Val Acc: 0.5574\n",
            "broccoli :  {'accuracy': 0.4246575342465753, 'recall': 0.62, 'precision': 0.5740740740740741, 'f1': 0.5961538461538461}\n",
            "carrot :  {'accuracy': 0.3050847457627119, 'recall': 0.4235294117647059, 'precision': 0.5217391304347826, 'f1': 0.4675324675324676}\n",
            "cucumber :  {'accuracy': 0.34210526315789475, 'recall': 0.52, 'precision': 0.5, 'f1': 0.5098039215686274}\n",
            "lemon :  {'accuracy': 0.37398373983739835, 'recall': 0.46, 'precision': 0.6666666666666666, 'f1': 0.544378698224852}\n",
            "pumpkin :  {'accuracy': 0.4748201438848921, 'recall': 0.7764705882352941, 'precision': 0.55, 'f1': 0.6439024390243903}\n",
            "Confusion Matrix:\n",
            "          broccoli  carrot    cucumber  lemon     pumpkin   \n",
            "broccoli  62        9         19        6         4         \n",
            "carrot    3         36        8         1         37        \n",
            "cucumber  28        8         52        12        0         \n",
            "lemon     14        8         19        46        13        \n",
            "pumpkin   1         8         6         4         66        \n",
            "Epoch [11/15], Train Loss: 1.3493, Train Acc: 0.5525\n",
            "Epoch [11/15], Val Loss: 1.3296, Val Acc: 0.5681\n",
            "Epoch [12/15], Train Loss: 1.3561, Train Acc: 0.5380\n",
            "Epoch [12/15], Val Loss: 1.3360, Val Acc: 0.5489\n",
            "Epoch [13/15], Train Loss: 1.3317, Train Acc: 0.5685\n",
            "Epoch [13/15], Val Loss: 1.3371, Val Acc: 0.5596\n",
            "Epoch [14/15], Train Loss: 1.3149, Train Acc: 0.5900\n",
            "Epoch [14/15], Val Loss: 1.3354, Val Acc: 0.5532\n",
            "Epoch [15/15], Train Loss: 1.3270, Train Acc: 0.5745\n",
            "Epoch [15/15], Val Loss: 1.3114, Val Acc: 0.5915\n",
            "broccoli :  {'accuracy': 0.45652173913043476, 'recall': 0.63, 'precision': 0.6237623762376238, 'f1': 0.6268656716417911}\n",
            "carrot :  {'accuracy': 0.425531914893617, 'recall': 0.7058823529411765, 'precision': 0.5172413793103449, 'f1': 0.5970149253731344}\n",
            "cucumber :  {'accuracy': 0.38095238095238093, 'recall': 0.56, 'precision': 0.5436893203883495, 'f1': 0.5517241379310345}\n",
            "lemon :  {'accuracy': 0.40601503759398494, 'recall': 0.54, 'precision': 0.6206896551724138, 'f1': 0.5775401069518717}\n",
            "pumpkin :  {'accuracy': 0.4368932038834951, 'recall': 0.5294117647058824, 'precision': 0.7142857142857143, 'f1': 0.6081081081081081}\n",
            "Confusion Matrix:\n",
            "          broccoli  carrot    cucumber  lemon     pumpkin   \n",
            "broccoli  63        9         18        10        0         \n",
            "carrot    4         60        8         1         12        \n",
            "cucumber  20        6         56        18        0         \n",
            "lemon     12        11        17        54        6         \n",
            "pumpkin   2         30        4         4         45        \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.327048110961914, 0.5745)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing out confusion matrix\n",
        "print_confusion_matrix(ground_truth_list, predicted_list, classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mop5HrA-ECze",
        "outputId": "1cd482b3-43ff-48e9-85bc-0c7c6eec6afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "          broccoli  carrot    cucumber  lemon     pumpkin   \n",
            "broccoli  822       131       299       187       61        \n",
            "carrot    52        637       70        81        435       \n",
            "cucumber  412       132       662       244       50        \n",
            "lemon     197       174       324       649       156       \n",
            "pumpkin   33        285       63        124       770       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tp, fp, fn = calcMetrics(ground_truth_list, predicted_list)"
      ],
      "metadata": {
        "id": "nXxMnDLHXOUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing out total of TP FP FN for each class\n",
        "for i in range(0, number_of_classes):\n",
        "  metrics = calculate_metrics(tp[classes[i].lower()], fp[classes[i].lower()], fn[classes[i].lower()])\n",
        "  print(classes[i].lower(), ': ', metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQz2zKCAEDGm",
        "outputId": "36e6c134-4cd2-41af-8e5e-8678dccfb8f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "broccoli :  {'accuracy': 0.37465815861440294, 'recall': 0.548, 'precision': 0.5422163588390502, 'f1': 0.5450928381962864}\n",
            "carrot :  {'accuracy': 0.3189784677015523, 'recall': 0.4996078431372549, 'precision': 0.4687270051508462, 'f1': 0.4836750189825361}\n",
            "cucumber :  {'accuracy': 0.29343971631205673, 'recall': 0.44133333333333336, 'precision': 0.46685472496473907, 'f1': 0.45373543522960935}\n",
            "lemon :  {'accuracy': 0.3038389513108614, 'recall': 0.43266666666666664, 'precision': 0.5050583657587548, 'f1': 0.4660682226211849}\n",
            "pumpkin :  {'accuracy': 0.3894790085988872, 'recall': 0.6039215686274509, 'precision': 0.5230978260869565, 'f1': 0.5606115762650162}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_len = len(tp)\n",
        "\n",
        "#Total of TP FP FN\n",
        "conjoined_statistics = add_up_statistics(tp, fp, fn)\n",
        "print(conjoined_statistics)\n",
        "\n",
        "#Overall metrics\n",
        "overall_metrics = calculate_overall_metrics(conjoined_statistics)\n",
        "print(overall_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VkZlFYJEKyM",
        "outputId": "22074954-2cc2-4a79-832c-8498fb9934ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tp': 4110, 'tn': 0, 'fp': 3470, 'fn': 3390}\n",
            "{'accuracy': 0.37465815861440294, 'recall': 0.548, 'precision': 0.5422163588390502, 'f1': 0.5450928381962864}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking if confusion matrix function works\n",
        "predicted_list1 = [0, 1, 2, 3, 4, 1, 1, 2, 0, 3, 3, 4, 0, 4, 0, 1, 2, 2, 3, 4]\n",
        "ground_truth_list1 = [0, 1, 2, 3, 4, 0, 0, 4, 0, 3, 4, 1, 1, 4, 2, 1, 2, 2, 4, 4]\n",
        "print_confusion_matrix(ground_truth_list1, predicted_list1, classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDes--BwuIx8",
        "outputId": "7f3af74e-f4dc-44a6-dc79-f3ad4780e2e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "          broccoli  carrot    cucumber  lemon     pumpkin   \n",
            "broccoli  2         2         0         0         0         \n",
            "carrot    1         2         0         0         1         \n",
            "cucumber  1         0         3         0         0         \n",
            "lemon     0         0         0         2         0         \n",
            "pumpkin   0         0         1         2         3         \n"
          ]
        }
      ]
    }
  ]
}